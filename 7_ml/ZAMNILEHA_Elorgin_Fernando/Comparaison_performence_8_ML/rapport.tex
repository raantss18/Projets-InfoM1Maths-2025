\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{booktabs}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{pdflscape}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[french]{babel}

% --- Paramètres du document ---
\title{\textbf{Rapport d'Analyse Comparative :\\ Évaluation de 8 Modèles de Machine Learning} \\ Analyse de Performance Data Science}
\author{ZAMANILEHA Elorgin Fernando}
% \date{\today}
\date{18 décembre 2025}

\begin{document}

\maketitle

\tableofcontents

\newpage

\section{Introduction}
Ce rapport présente une analyse complète des données sur les transactions par carte de crédit pour la détection de fraude, basée sur les fichiers fournis : un ensemble de données CSV (\texttt{credit\_card\_fraud\_10k.csv}), un fichier de résultats de modèles (\texttt{model\_comparison\_results\_sklearn.csv}), et un notebook Jupyter (\texttt{performance.ipynb}). Le rapport couvre les étapes suivantes :
\begin{itemize}
    \item Analyse et nettoyage des données.
    \item Comparaison des 8 modèles d'apprentissage automatique.
    \item Discussion détaillée de chaque résultat.
    \item Validation additionnelle.
\end{itemize}
Les visualisations fournies (importance des features, comparaison des performances, et radar chart) sont intégrées aux sections appropriées pour illustrer les résultats.

\section{Analyse et Nettoyage des Données}
Cette section décrit l'analyse initiale des données à partir du notebook Jupyter et du fichier CSV \texttt{credit\_card\_fraud\_10k.csv}.

\subsection{Description des Données}
Les données contiennent 10 000 transactions par carte de crédit, avec les colonnes suivantes :
\begin{itemize}
    \item \texttt{transaction\_id} : Identifiant unique (entier).
    \item \texttt{amount} : Montant de la transaction (flottant).
    \item \texttt{transaction\_hour} : Heure de la transaction (entier, 0-23).
    \item \texttt{merchant\_category} : Catégorie du marchand (chaîne : Electronics, Travel, Grocery, Food, Clothing).
    \item \texttt{foreign\_transaction} : Transaction étrangère (0/1).
    \item \texttt{location\_mismatch} : Incohérence de localisation (0/1).
    \item \texttt{device\_trust\_score} : Score de confiance du dispositif (entier).
    \item \texttt{velocity\_last\_24h} : Vélocité des transactions dernières 24h (entier).
    \item \texttt{cardholder\_age} : Âge du titulaire de la carte (entier).
    \item \texttt{is\_fraud} : Indicateur de fraude (0/1, cible).
\end{itemize}

Dimensions : 10 000 lignes, 10 colonnes.

Types de données :
\begin{verbatim}
transaction_id           int64
amount                 float64
transaction_hour         int64
merchant_category       object
foreign_transaction      int64
location_mismatch        int64
device_trust_score       int64
velocity_last_24h        int64
cardholder_age           int64
is_fraud                 int64
\end{verbatim}

Aucune valeur manquante n'a été détectée.

\subsection{Statistiques Descriptives}
Les statistiques clés incluent :
\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\toprule
 & transaction\_id & amount & transaction\_hour & foreign\_transaction & ... \\
\midrule
count & 10000.00000 & 10000.000000 & 10000.000000 & 10000.000000 & ... \\
mean & 5000.50000 & 175.949849 & 11.593300 & 0.097800 & ... \\
std & 2886.89568 & 175.392827 & 6.922708 & 0.297059 & ... \\
min & 1.00000 & 0.000000 & 0.000000 & 0.000000 & ... \\
25\% & 2500.75000 & 50.905000 & 6.000000 & 0.000000 & ... \\
50\% & 5000.50000 & 122.000000 & 12.000000 & 0.000000 & ... \\
75\% & 7500.25000 & 249.487500 & 17.000000 & 0.000000 & ... \\
max & 10000.00000 & 1370.040000 & 23.000000 & 1.000000 & ... \\
\bottomrule
\end{tabular}
\caption{Statistiques descriptives des données (extrait).}
\label{tab:stats}
\end{table}

\subsection{Nettoyage des Données}
Dans le notebook, les étapes de nettoyage incluent :
- Encodage des variables catégorielles (\texttt{merchant\_category}) via \texttt{LabelEncoder}.
- Normalisation des features numériques avec \texttt{StandardScaler}.
- Division des données en ensembles d'entraînement (80\%) et de test (20\%) via \texttt{train\_test\_split}.
- Gestion du déséquilibre des classes (fraudes rares : environ 0.3\% des transactions sont frauduleuses, basé sur l'échantillon).

Aucune imputation n'était nécessaire en raison de l'absence de valeurs manquantes. Les outliers potentiels (e.g., montants élevés) n'ont pas été traités explicitement, mais la normalisation aide à les atténuer.

\subsection{Importance des Features (AdaBoost)}
La visualisation suivante montre l'importance des features pour le modèle AdaBoost :

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{importance_des_features_adaboost.png}
\caption{Importance des features pour AdaBoost.}
\label{fig:importance}
\end{figure}

Discussion : Les features les plus importantes sont \texttt{transaction\_hour}, \texttt{foreign\_transaction}, et \texttt{device\_trust\_score}. Cela suggère que les transactions nocturnes, étrangères, ou avec un faible score de confiance sont des indicateurs clés de fraude. Les features comme \texttt{merchant\_category} et \texttt{cardholder\_age} ont une importance moindre.

\newpage

\section{Comparaison des 8 Modèles}
Huit modèles ont été entraînés et comparés : Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, AdaBoost, Extra Trees, SVM, et K-Nearest Neighbors. Les hyperparamètres ont été optimisés via \texttt{GridSearchCV} ou \texttt{RandomizedSearchCV}.

\subsection{Résultats des Modèles}
Les résultats sont extraits du fichier \texttt{model\_comparison\_results\_sklearn.csv} :

% \begin{landscape}
\begin{center}
\small
\begin{longtable}{p{1.6cm}p{1.1cm}p{1.2cm}p{1.1cm}p{1.2cm}p{1.2cm}p{1.2cm}p{1.2cm}p{1.2cm}p{3cm}}
\toprule
Model & Accuracy & Precision & Recall & F1-Score & ROC-AUC & CV Mean F1 & CV Std F1 & Training Time (s) & Best Params \\
\midrule
Logistic Regression & 0.9585 & 0.2655 & 1.0000 & 0.4196 & 0.9927 & 0.4214 & 0.0302 & 122.4534 & \{'C': 10, 'solver': 'liblinear'\} \\
\midrule
Decision Tree & 0.9995 & 0.9677 & 1.0000 & 0.9836 & 0.9997 & 0.9166 & 0.0522 & 6.0193 & \{'max\_depth': 10, 'min\_samples\_split': 2\} \\
\midrule
Random Forest & 0.9940 & 1.0000 & 0.6000 & 0.7500 & 0.9999 & 0.6159 & 0.0521 & 86.1845 & \{'max\_depth': 10, 'n\_estimators': 100\} \\
\midrule
Gradient Boosting & 0.9995 & 0.9677 & 1.0000 & 0.9836 & 1.0000 & 0.9468 & 0.0419 & 717.0001 & \{'learning\_rate': 0.1, 'max\_depth': 5, 'n\_estimators': 200\} \\
\midrule
AdaBoost & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 0.9957 & 0.0085 & 264.7728 & \{'learning\_rate': 0.5, 'n\_estimators': 100\} \\
\midrule
Extra Trees & 0.9940 & 0.7500 & 0.9000 & 0.8182 & 0.9981 & 0.4725 & 0.0786 & 358.1641 & \{'max\_depth': 10, 'n\_estimators': 200\} \\
\midrule
SVM & 0.9915 & 0.6757 & 0.8333 & 0.7463 & 0.9942 & 0.6971 & 0.0275 & 1128.8543 & \{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'\} \\
\midrule
K-Nearest Neighbors & 0.9875 & 0.6190 & 0.4333 & 0.5098 & 0.8948 & 0.3442 & 0.1176 & 40.6540 & \{'n\_neighbors': 3, 'weights': 'distance'\} \\
\bottomrule
\caption{Résultats de comparaison des modèles.}
\label{tab:comparison}
\end{longtable}
\normalsize
\end{center}
% \end{landscape}

\subsection{Visualisation de la Comparaison}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{plot_comparison.png}
\caption{Comparaison des performances des modèles (F1-Score, ROC-AUC, Temps d'entraînement, etc.).}
\label{fig:comparison}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{radar_chart.png}
\caption{Radar Chart des 3 meilleurs modèles (AdaBoost, Decision Tree, Gradient Boosting).}
\label{fig:radar}
\end{figure}

\newpage

\section{Discussion de Chaque Résultat}
\subsection{Logistic Regression}
Accuracy : 95.85\%, F1-Score : 0.42, ROC-AUC : 0.99. Discussion : Ce modèle basique performe bien en accuracy globale mais peine sur les classes minoritaires (fraudes), avec un faible precision pour la classe 1. Il est rapide mais inadapté au déséquilibre. Le CV Mean F1 (0.42) confirme une variabilité modérée.

\subsection{Decision Tree}
Accuracy : 99.95\%, F1-Score : 0.98, ROC-AUC : 0.9997. Discussion : Excellent rappel (1.0) pour les fraudes, mais risque de surajustement. Le temps d'entraînement court (6s) et les params optimaux (max\_depth=10) le rendent efficace. CV Mean F1 élevé (0.92) avec faible variance.

\subsection{Random Forest}
Accuracy : 99.40\%, F1-Score : 0.75, ROC-AUC : 0.9999. Discussion : Parfait precision (1.0) mais faible rappel (0.6), manquant des fraudes. Ensemble d'arbres réduit le surajustement, mais CV Mean F1 moyen (0.62) indique une sensibilité au déséquilibre.

\subsection{Gradient Boosting}
Accuracy : 99.95\%, F1-Score : 0.98, ROC-AUC : 1.0. Discussion : Similaire à Decision Tree, mais plus robuste grâce au boosting. Temps long (717s), mais CV Mean F1 (0.95) excellent. Idéal pour la détection de fraude.

\subsection{AdaBoost}
Accuracy : 100\%, F1-Score : 1.0, ROC-AUC : 1.0. Discussion : Performances parfaites sur le test set. Le boosting adaptatif excelle sur les données déséquilibrées. CV Mean F1 (0.996) avec faible std (0.0085) montre une grande stabilité. Meilleur modèle global.

\subsection{Extra Trees}
Accuracy : 99.40\%, F1-Score : 0.82, ROC-AUC : 0.9981. Discussion : Bon équilibre precision/recall, mais CV Mean F1 faible (0.47) indique une performance variable. Temps modéré (358s).

\subsection{SVM}
Accuracy : 99.15\%, F1-Score : 0.75, ROC-AUC : 0.9942. Discussion : Bon pour les marges, mais lent (1128s). CV Mean F1 (0.70) moyen ; sensible aux hyperparamètres (kernel RBF).

\subsection{K-Nearest Neighbors}
Accuracy : 98.75\%, F1-Score : 0.51, ROC-AUC : 0.8948. Discussion : Faible performance sur les fraudes (recall 0.43). CV Mean F1 bas (0.34) avec haute variance ; non adapté aux grands ensembles.

Globalement, les modèles de boosting (AdaBoost, Gradient Boosting) surpassent les autres en raison de leur gestion du déséquilibre.

\newpage

\section{Validation Additionnelle}
Une validation additionnelle sur l'ensemble de test confirme les résultats :

\begin{table}[H]
\centering
\begin{tabular}{p{1.7cm}rrrrrrrp{1.5cm}}
\toprule
Model & Accuracy & Precision\_0 & Precision\_1 & Recall\_0 & Recall\_1 & F1\_0 & F1\_1 & ROC\_AUC \\
\midrule
Logistic Regression & 0.9585 & 1.0000 & 0.2655 & 0.9585 & 1.0000 & 0.9785 & 0.4196 & 0.9927 \\
Decision Tree & 0.9995 & 1.0000 & 0.9677 & 0.9997 & 1.0000 & 0.9997 & 0.9836 & 0.9997 \\
Random Forest & 0.9940 & 0.9940 & 1.0000 & 1.0000 & 0.6000 & 0.9970 & 0.7500 & 0.9999 \\
Gradient Boosting & 0.9995 & 1.0000 & 0.9677 & 0.9997 & 1.0000 & 0.9997 & 0.9836 & 1.0000 \\
AdaBoost & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 \\
Extra Trees & 0.9940 & 0.9954 & 0.7500 & 0.9969 & 0.9000 & 0.9962 & 0.8182 & 0.9981 \\
SVM & 0.9915 & 0.9939 & 0.6757 & 0.9957 & 0.8333 & 0.9948 & 0.7463 & 0.9942 \\
K-Nearest Neighbors & 0.9875 & 0.9959 & 0.6190 & 0.9937 & 0.4333 & 0.9948 & 0.5098 & 0.8948 \\
\bottomrule
\end{tabular}
\caption{Résultats de validation additionnelle.}
\label{tab:validation}
\end{table}

Discussion : Les métriques détaillées (par classe) confirment qu'AdaBoost est parfait. Les modèles comme KNN et Logistic Regression luttent avec la classe minoritaire (fraude), soulignant l'importance du recall pour la détection de fraude.

\section{Conclusion}
AdaBoost émerge comme le meilleur modèle pour la détection de fraude, avec des performances parfaites. Des améliorations futures pourraient inclure le suréchantillonnage (e.g., SMOTE) pour les modèles plus faibles. Les visualisations soulignent l'importance des features temporelles et de confiance.

\end{document}